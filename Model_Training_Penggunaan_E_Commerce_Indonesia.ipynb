{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analisis Sentimen Pengguna Aplikasi E-Commerce di Indonesia"
      ],
      "metadata": {
        "id": "IGEJBjzEYNxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada file ini dilakukan proses pelatihan model berdasarkan dataset yang telah diperoleh sebelumnya dari hasil scraping."
      ],
      "metadata": {
        "id": "4G4FeCNvq-6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Instalasi dan Import Library"
      ],
      "metadata": {
        "id": "q58KhRGippl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dilakukan instalasi library Natural Language Toolkit (NLTK) untuk pemrosesan bahasa alami, sedangkan Sastrawi untuk stemming kata kata berbahasa Indonesia. Kemudian import library yang dibutuhkan, seperti library standar, NLTK dan Sastrawi, Scikit-learn, dan Tensor Flow."
      ],
      "metadata": {
        "id": "_lY_dz94qpCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalasi NLTK dan Sastrawi\n",
        "!pip install nltk Sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-myxOGoxPik",
        "outputId": "c8cff350-7c35-443f-980d-4c8f5c380dce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RbCgX2BpmiK0"
      },
      "outputs": [],
      "source": [
        "#Import library yang dibutuhkan\n",
        "\n",
        "#Library standar\n",
        "import re\n",
        "import string\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#NLTK dan Sastrawi untuk NLP Bahasa Indonesia\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "#Preprocessing & machine learning dengan Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "#Model dari Scikit-learn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Deep Learning dengan TensorFlow/Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Dataset\n"
      ],
      "metadata": {
        "id": "D0nqc-HApyI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dataset dimuat dari URL ke dalam DataFrame menggunakan kemudian menampilkan lima baris pertama untuk memverifikasi struktur data sebelum tahap analisis atau pemrosesan lebih lanjut."
      ],
      "metadata": {
        "id": "eeXhQLXjwgIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/LailaWulandarii/Dicoding-Resources/refs/heads/main/ecommerce_reviews_labeled.csv')\n",
        "\n",
        "#Menampilkan 5 data teratas\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5TFAAjs2wHtd",
        "outputId": "eae53d6e-95d6-4f65-c8d9-f6a98c7ecc5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Username  Rating                                             Review  \\\n",
              "0  Pengguna Google       1  kokgitu banyak perodak yg laku tapi komisi tid...   \n",
              "1  Pengguna Google       5  gw suka banget sama shopee pengantarannya cepa...   \n",
              "2  Pengguna Google       5                                              bagus   \n",
              "3  Pengguna Google       5                                             Mantap   \n",
              "4  Pengguna Google       5                                        sangat puas   \n",
              "\n",
              "      App  \n",
              "0  Shopee  \n",
              "1  Shopee  \n",
              "2  Shopee  \n",
              "3  Shopee  \n",
              "4  Shopee  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f55ddc6-8240-41b1-a33a-5b3833cab1d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Username</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review</th>\n",
              "      <th>App</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>1</td>\n",
              "      <td>kokgitu banyak perodak yg laku tapi komisi tid...</td>\n",
              "      <td>Shopee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>5</td>\n",
              "      <td>gw suka banget sama shopee pengantarannya cepa...</td>\n",
              "      <td>Shopee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>5</td>\n",
              "      <td>bagus</td>\n",
              "      <td>Shopee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>5</td>\n",
              "      <td>Mantap</td>\n",
              "      <td>Shopee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>5</td>\n",
              "      <td>sangat puas</td>\n",
              "      <td>Shopee</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f55ddc6-8240-41b1-a33a-5b3833cab1d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f55ddc6-8240-41b1-a33a-5b3833cab1d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f55ddc6-8240-41b1-a33a-5b3833cab1d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb861720-0af6-4d4a-a80b-a2c0e565ad09\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb861720-0af6-4d4a-a80b-a2c0e565ad09')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb861720-0af6-4d4a-a80b-a2c0e565ad09 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 14639,\n  \"fields\": [\n    {\n      \"column\": \"Username\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4479,\n        \"samples\": [\n          \"Arya Bima\",\n          \"Aunisyafia Aunisyafia\",\n          \"Muhammad' Dun\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13393,\n        \"samples\": [\n          \"mantaap lanjut...lazada maju terus\",\n          \"e-commerce besar,tapi pelit ongkir\",\n          \"Pelayan busuk mending shope apa toped aja aman\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"App\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Shopee\",\n          \"Tokopedia\",\n          \"Lazada\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preprocessing"
      ],
      "metadata": {
        "id": "ftm1YteMpzkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dilakukann preprocessing untuk membersihkan dan mengoptimalkan data sebelum analisis lebih lanjut."
      ],
      "metadata": {
        "id": "0HaUdnCOsXfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mengunduh stopwords Bahasa Indonesia\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "\n",
        "#Membuat stopwords custom\n",
        "custom_stopwords = ['yg', 'nya', 'aja', 'kok', 'banget', 'dll']\n",
        "stop_words.update(custom_stopwords)\n",
        "\n",
        "#Membuat stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "#Fungsi untuk membersihkan teks\n",
        "def clean_text(text):\n",
        "    #Mengubah teks menjadi huruf kecil\n",
        "    text = text.lower()\n",
        "    #Menghapus tautan\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    #Menghapus karakter non-ASCII\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "    #Menghapus angka\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    #Menghapus tanda baca\n",
        "    text = re.sub(rf\"[{re.escape(string.punctuation)}]\", '', text)\n",
        "    #Menghapus spasi berlebih\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "#Fungsi preprocessing lengkap\n",
        "def preprocess_text(text):\n",
        "    text = clean_text(text)\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    text = ' '.join(words)\n",
        "    text = stemmer.stem(text)\n",
        "    return text\n",
        "\n",
        "#Memastikan kolom Review berupa string\n",
        "df['Review'] = df['Review'].astype(str)\n",
        "#Menyimpan hasil preprocessing\n",
        "df['cleaned_review'] = df['Review'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "5OYdqWRcnByc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2be4c89-6c9a-4c4c-d69b-8329c0e97a08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis Preprocessing:\n",
        "\n",
        "1. Stopwords: Mengunduh stopwords Bahasa Indonesia dari NLTK dan menambahkan kata-kata tidak formal seperti \"yg\", \"aja\", dan lainnya. Stopwords ini dihapus karena tidak memberikan informasi penting dalam analisis.\n",
        "2. Stemming: Menggunakan library Sastrawi untuk mengubah kata ke bentuk dasarnya agar menjaga konsistensi teks.\n",
        "3. Pembersihan Teks: Fungsi clean_text menghapus tautan, karakter non-ASCII (emoji), angka, tanda baca, dan spasi berlebih, serta mengubah teks menjadi huruf kecil.\n",
        "4. Preprocessing Lengkap: Fungsi preprocess_text menjalankan semua proses di atas — pembersihan, penghapusan stopwords, dan stemming.\n",
        "5. Penerapan: Fungsi preprocess_text diterapkan ke kolom Review (yang telah dipastikan berupa string), lalu hasilnya disimpan di kolom baru cleaned_review untuk digunakan pada tahap analisis berikutnya.\n",
        "\n"
      ],
      "metadata": {
        "id": "vCdbrXucpnwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Labeling Data"
      ],
      "metadata": {
        "id": "rr67NCFuqDru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dilakukann labeling data agar bisa digunakan untuk pelatihan model machine learning atau deep learning."
      ],
      "metadata": {
        "id": "oqrQyWiStnln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi untuk menentukan sentimen berdasarkan teks dan rating\n",
        "def sentimen(text, rating):\n",
        "    #Mengubah teks menjadi huruf kecil\n",
        "    text = text.lower()\n",
        "    #Mengonversi rating menjadi integer\n",
        "    rating = int(rating)\n",
        "\n",
        "    #Daftar kata-kata positif, negatif, dan netral\n",
        "    positif_words = [\n",
        "        \"bagus\", \"mantap\", \"suka\", \"puas\", \"cepat\", \"oke\", \"top\", \"baik\", \"luar biasa\", \"hebat\",\n",
        "        \"keren\", \"memuaskan\", \"terbaik\", \"recommended\", \"sangat membantu\", \"praktis\", \"fungsi dengan baik\",\n",
        "        \"worth it\", \"bagus banget\", \"bagus sekali\", \"terpercaya\", \"responsif\", \"efisien\", \"professional\",\n",
        "        \"mudah\", \"mudah digunakan\", \"terjangkau\", \"efektif\"\n",
        "    ]\n",
        "\n",
        "    negatif_words = [\n",
        "        \"jelek\", \"buruk\", \"kecewa\", \"lambat\", \"parah\", \"benci\", \"sampah\", \"menyesal\", \"rip\",\n",
        "        \"bug\", \"crash\", \"lemot\", \"gagal\", \"tidak berfungsi\", \"tidak sesuai\", \"pelayanan buruk\",\n",
        "        \"respon lama\", \"mengecewakan\", \"tidak puas\", \"ribet\", \"tidak worth it\", \"lama banget\",\n",
        "        \"error\", \"hang\", \"tidak stabil\", \"tidak aman\", \"tidak profesional\", \"sulit\", \"tidak efektif\"\n",
        "    ]\n",
        "\n",
        "    netral_words = [\n",
        "        \"biasa saja\", \"lumayan\", \"cukup\", \"standar\", \"so-so\", \"not bad\", \"oke lah\", \"agak bagus\", \"agak buruk\",\n",
        "        \"tidak terlalu bagus\", \"tidak terlalu buruk\", \"seadanya\", \"netral\", \"nothing special\", \"tidak istimewa\"\n",
        "    ]\n",
        "\n",
        "    #Memeriksa apakah ada kata dari kategori positif, negatif, atau netral\n",
        "    has_pos = any(word in text for word in positif_words)\n",
        "    has_neg = any(word in text for word in negatif_words)\n",
        "    has_net = any(word in text for word in netral_words)\n",
        "\n",
        "    #Menentukan label berdasarkan rating dan kata-kata yang ditemukan\n",
        "    if rating <= 2 or has_neg:\n",
        "        return \"Negatif\"\n",
        "    elif rating == 3 or has_net:\n",
        "        return \"Netral\"\n",
        "    elif rating >= 4 or has_pos:\n",
        "        return \"Positif\"\n",
        "    else:\n",
        "        return \"Netral\"\n",
        "\n",
        "#Menerapkan fungsi sentimen ke DataFrame\n",
        "df['label'] = df.apply(lambda row: sentimen(row['cleaned_review'], row['Rating']), axis=1)\n",
        "\n",
        "#Mengonversi kolom label menjadi kategori terurut\n",
        "df['label'] = pd.Categorical(\n",
        "    df['label'],\n",
        "    categories=[\"Negatif\", \"Netral\", \"Positif\"],\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "#Cek distribusi label\n",
        "print(df['label'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGvX3YdWpRzZ",
        "outputId": "873c6ee7-9016-4cb7-a9d8-7811eddf4f37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "Negatif    5179\n",
            "Netral      719\n",
            "Positif    8741\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labeling dilakukan dengan mencocokkan teks review (yang sudah dibersihkan dan diubah ke huruf kecil) terhadap daftar kata positif, negatif, dan netral, serta mempertimbangkan nilai rating. Hasil klasifikasi dibagi menjadi tiga label:\n",
        "1. Positif: Rating ≥ 4 atau mengandung kata positif\n",
        "2. Negatif: Rating ≤ 2 atau mengandung kata negatif\n",
        "3. Netral: Rating = 3 atau mengandung kata netral\n",
        "\n",
        "Label disimpan dalam kolom label dan dikonversi ke format kategori terurut.\n",
        "\n",
        "Distribusi label:\n",
        "\n",
        "1. Positif: 8.741\n",
        "2. Netral: 719\n",
        "3. Negatif: 5.179\n",
        "\n",
        "Distribusi ini menunjukkan bahwa sebagian besar pengguna memberikan review yang bersifat positif terhadap aplikasi e-commerce, sementara review netral jumlahnya paling sedikit."
      ],
      "metadata": {
        "id": "kLtixbHgqmXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Skema Pelatihan Model Sentimen"
      ],
      "metadata": {
        "id": "wzSgVLcnvS3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada bagian ini, dilakukan evaluasi beberapa model untuk klasifikasi sentimen teks ulasan dan rating. Eksperimen dilakukan dengan menggunakan berbagai algoritma, termasuk Logistic Regression, Linear Support Vector Classification (SVC), dan Random Forest, serta model Deep Learning berbasis Multi-Layer Perceptron (MLP)."
      ],
      "metadata": {
        "id": "4yPbTjfB4QYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Linear Support Vector Classification (SVC) dengan TF-IDF"
      ],
      "metadata": {
        "id": "bnPJd4KZvg4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skema ini menggunakan pendekatan Linear Support Vector Classification (SVC) untuk klasifikasi sentimen tiga kelas (Negatif, Netral, Positif). Ulasan teks yang telah dibersihkan digabungkan dengan nilai rating numerik untuk menciptakan fitur gabungan yang kemudian diolah menggunakan TF-IDF sebagai teknik ekstraksi fitur."
      ],
      "metadata": {
        "id": "CNy9uX_55hzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi utama untuk memproses model\n",
        "def train_and_evaluate_model(df):\n",
        "    #Menggabungkan review dengan rating untuk fitur tambahan\n",
        "    df['review_with_rating'] = df['cleaned_review'] + \" \" + df['Rating'].astype(str)\n",
        "\n",
        "    #Ekstraksi fitur dengan TF-IDF Vectorization dengan membatasi jumlah kata unik untuk menghindari overfitting\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['review_with_rating'])\n",
        "    # Menyiapkan label target yang sudah dikategorikan (Negatif, Netral, Positif)\n",
        "    y = df['label']\n",
        "\n",
        "    #Membagi dataset menjadi 80% data latih dan 20% data uji dan random rtate 42\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    #Melatih model klasifikasi menggunakan LinearSVC\n",
        "    model = LinearSVC(C=1, max_iter=5000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    #Melakukan prediksi terhadap data latih dan data uji\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    #Evaluasi performa model menggunakan akurasi dan classification report\n",
        "    print(\"=== EVALUASI MODEL SVM (3 Label) ===\")\n",
        "    print(f\"Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "    print(f\"Testing Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(\"\\n--- Classification Report (Testing Set) ---\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    #Mengembalikan model dan vectorizer untuk digunakan pada inference\n",
        "    return model, vectorizer"
      ],
      "metadata": {
        "id": "vugYxdP5ciGY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model LinearSVC digunakan untuk klasifikasi sentimen berdasarkan review dan rating. Data diproses dengan menggabungkan review yang telah dibersihkan dengan rating, lalu diubah menjadi vektor menggunakan TfidfVectorizer. Model dilatih dengan data pelatihan dan diuji pada data uji untuk mengevaluasi akurasi dan menghasilkan laporan klasifikasi."
      ],
      "metadata": {
        "id": "1Nqe4xI68Vc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi untuk melakukan inference pada teks baru\n",
        "def perform_inference(model, vectorizer, sample_text, sample_rating):\n",
        "    #Menggabungkan teks dan rating menjadi satu input untuk analisis\n",
        "    sample_input = sample_text + \" \" + str(sample_rating)\n",
        "    #Transformasi input ke dalam format vektor menggunakan vectorizer yang sudah dilatih\n",
        "    sample_vector = vectorizer.transform([sample_input])\n",
        "    #Melakukan prediksi menggunakan model\n",
        "    sample_pred = model.predict(sample_vector)\n",
        "    #Menampilkan hasil prediksi\n",
        "    print(f\"Teks: {sample_text}\")\n",
        "    print(f\"Rating: {sample_rating}\")\n",
        "    print(f\"Hasil Prediksi Sentimen: {sample_pred[0]}\")"
      ],
      "metadata": {
        "id": "RdmrVoym3S7b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi perform_inference bertujuan untuk memproses teks baru yang diberikan bersama dengan ratingnya dan menghasilkan prediksi sentimen berdasarkan model yang sudah dilatih. Teks dan rating digabungkan untuk memberikan konteks yang lebih lengkap bagi model, lalu diubah menjadi vektor melalui TF-IDF vectorizer. Prediksi dilakukan dengan menggunakan model SVM yang telah dilatih, dan hasil sentimen yang diprediksi ditampilkan (Negatif, Positif, atau Netral)."
      ],
      "metadata": {
        "id": "c-cCvEbh9a48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Menjalankan inference\n",
        "if __name__ == \"__main__\":\n",
        "    model, vectorizer = train_and_evaluate_model(df)\n",
        "\n",
        "    #Sample Inference (teks & rating)\n",
        "    sample_texts = [\n",
        "        \"tidak puas dengan aplikasi ini, jelek, dan banyak bug\",\n",
        "        \"saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\",\n",
        "        \"fitur aplikasi standar\"\n",
        "    ]\n",
        "\n",
        "    sample_ratings = [2, 4, 3]\n",
        "\n",
        "    #Menjalankan inference untuk setiap teks sampel\n",
        "    for i in range(len(sample_texts)):\n",
        "        print(f\"\\n--- Inference Sample {i+1} ---\")\n",
        "        perform_inference(model, vectorizer, sample_texts[i], sample_ratings[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAkheQuj3Vrd",
        "outputId": "cb740557-a058-475c-8d62-c11c7e8896a0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== EVALUASI MODEL SVM (3 Label) ===\n",
            "Training Accuracy: 0.9497\n",
            "Testing Accuracy: 0.8528\n",
            "\n",
            "--- Classification Report (Testing Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Negatif       0.83      0.81      0.82      1032\n",
            "      Netral       0.68      0.15      0.24       142\n",
            "     Positif       0.87      0.94      0.90      1754\n",
            "\n",
            "    accuracy                           0.85      2928\n",
            "   macro avg       0.79      0.63      0.65      2928\n",
            "weighted avg       0.85      0.85      0.84      2928\n",
            "\n",
            "\n",
            "--- Inference Sample 1 ---\n",
            "Teks: tidak puas dengan aplikasi ini, jelek, dan banyak bug\n",
            "Rating: 2\n",
            "Hasil Prediksi Sentimen: Negatif\n",
            "\n",
            "--- Inference Sample 2 ---\n",
            "Teks: saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\n",
            "Rating: 4\n",
            "Hasil Prediksi Sentimen: Positif\n",
            "\n",
            "--- Inference Sample 3 ---\n",
            "Teks: fitur aplikasi standar\n",
            "Rating: 3\n",
            "Hasil Prediksi Sentimen: Netral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model LinearSVC mencapai akurasi training 94.97% dan testing 85.28%, menunjukkan generalisasi yang baik.\n",
        "Performa terbaik ada di kelas Positif (f1-score: 0.90), diikuti Negatif (0.82).\n",
        "Kelas Netral lemah (f1-score: 0.24) akibat recall rendah (0.15), kemungkinan karena data tidak seimbang.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Hasil analisis inference:\n",
        "\n",
        "1. Sample 1:\n",
        "  * Teks: \"tidak puas dengan aplikasi ini, jelek, dan banyak bug\"\n",
        "  * Rating: 2\n",
        "  * Hasil Prediksi Sentimen: Negatif\n",
        "\n",
        "  Kesimpulan: Model berhasil mendeteksi sentimen negatif dengan tepat, berdasarkan kata-kata yang mengandung ketidakpuasan seperti \"jelek\" dan \"banyak bug.\"\n",
        "2. Sample 2:\n",
        "  * Teks: \"saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\"\n",
        "  * Rating: 4\n",
        "  * Hasil Prediksi Sentimen: Positif\n",
        "\n",
        "  Kesimpulan: Model berhasil mengidentifikasi sentimen positif dengan baik, berkat kata-kata yang menunjukkan pengalaman pengguna yang memuaskan seperti \"sangat membantu\" dan \"mudah digunakan.\"\n",
        "3. Sample 3:\n",
        "  * Teks: \"fitur aplikasi standar\"\n",
        "  * Rating: 3\n",
        "  * Hasil Prediksi Sentimen: Netral\n",
        "\n",
        "  Kesimpulan:  Model berhasil mengidentifikasi sentimen netral dengan baik, berkat kata \"standar\" yang menggambarkan pengalaman pengguna.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Penerapan model pada tiga sample teks dari scraping review Play Store untuk aplikasi e-commerce menunjukkan kemampuan model dalam mengklasifikasikan sentimen—Negatif, Positif, dan Netral—berdasarkan isi review dan rating yang diberikan. Model ini efektif digunakan untuk analisis sentimen real-time, memberikan wawasan berharga mengenai feedback pengguna dan penilaian aplikasi e-commerce."
      ],
      "metadata": {
        "id": "9hYvcNRhkVmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Logistic Regression dengan TF-IDF"
      ],
      "metadata": {
        "id": "GWtquiZcvqef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi utama untuk memproses model\n",
        "def train_and_evaluate_model(df):\n",
        "    #Menggabungkan review dengan rating untuk fitur tambahan\n",
        "    df['review_with_rating'] = df['cleaned_review'] + \" \" + df['Rating'].astype(str)\n",
        "\n",
        "    #Ekstraksi fitur dengan TF-IDF Vectorization dengan membatasi jumlah kata unik untuk menghindari overfitting\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['review_with_rating'])\n",
        "    #Menyiapkan label target yang sudah dikategorikan (Negatif, Netral, Positif)\n",
        "    y = df['label']\n",
        "\n",
        "    #Membagi dataset menjadi 80% data latih dan 20% data uji dan random rtate 42\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    #Melatih model menggunakan Logistic Regression\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    #Melakukan prediksi terhadap data latih dan data uji\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    #Evaluasi performa model menggunakan akurasi dan classification report\n",
        "    print(\"=== EVALUASI MODEL LOGISTIC REGRESSION ===\")\n",
        "    print(f\"Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "    print(f\"Testing Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(\"\\n--- Classification Report (Testing Set) ---\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    return model, vectorizer\n"
      ],
      "metadata": {
        "id": "BZyfmWkaZC2J"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Logistic Regression digunakan untuk klasifikasi sentimen berdasarkan review dan rating. Data diproses dengan menggabungkan review yang telah dibersihkan dengan rating, lalu diubah menjadi vektor menggunakan TfidfVectorizer. Model dilatih dengan data pelatihan dan diuji pada data uji untuk mengevaluasi akurasi dan menghasilkan laporan klasifikasi."
      ],
      "metadata": {
        "id": "PHzDhu6sfbUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi untuk melakukan inference pada teks baru\n",
        "def perform_inference(model, vectorizer, sample_text, sample_rating):\n",
        "    #Menggabungkan teks dan rating menjadi satu input untuk analisis\n",
        "    sample_input = sample_text + \" \" + str(sample_rating)\n",
        "    #Transformasi input ke dalam format vektor menggunakan vectorizer yang sudah dilatih\n",
        "    sample_vector = vectorizer.transform([sample_input])\n",
        "    #Melakukan prediksi menggunakan model\n",
        "    sample_pred = model.predict(sample_vector)\n",
        "    #Menampilkan hasil prediksi\n",
        "    print(f\"Teks: {sample_text}\")\n",
        "    print(f\"Rating: {sample_rating}\")\n",
        "    print(f\"Hasil Prediksi Sentimen: {sample_pred[0]}\")"
      ],
      "metadata": {
        "id": "uXhUBZqaeb81"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi perform_inference bertujuan untuk memproses teks baru yang diberikan bersama dengan ratingnya dan menghasilkan prediksi sentimen berdasarkan model yang sudah dilatih. Teks dan rating digabungkan untuk memberikan konteks yang lebih lengkap bagi model, lalu diubah menjadi vektor melalui TF-IDF vectorizer. Prediksi dilakukan dengan menggunakan model SVM yang telah dilatih, dan hasil sentimen yang diprediksi ditampilkan (Negatif, Positif, atau Netral)."
      ],
      "metadata": {
        "id": "EbY6SM1wfxMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Menjalankan inference dan evaluasi\n",
        "if __name__ == \"__main__\":\n",
        "    model, vectorizer = train_and_evaluate_model(df)\n",
        "\n",
        "    #Sample Inference (teks & rating)\n",
        "    sample_texts = [\n",
        "        \"tidak puas dengan aplikasi ini, jelek, dan banyak bug\",\n",
        "        \"saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\",\n",
        "        \"fitur aplikasi standar\"\n",
        "    ]\n",
        "\n",
        "    sample_ratings = [2, 4, 3]\n",
        "\n",
        "    #Menjalankan inference setiap teks sampel\n",
        "    for i in range(len(sample_texts)):\n",
        "        print(f\"\\n--- Inference Sample {i+1} ---\")\n",
        "        perform_inference(model, vectorizer, sample_texts[i], sample_ratings[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3914419a-4eae-451e-be25-580d33e1ec01",
        "id": "r0vX6ofFecLh"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== EVALUASI MODEL LOGISTIC REGRESSION ===\n",
            "Training Accuracy: 0.8968\n",
            "Testing Accuracy: 0.8600\n",
            "\n",
            "--- Classification Report (Testing Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Negatif       0.84      0.82      0.83      1032\n",
            "      Netral       0.88      0.11      0.19       142\n",
            "     Positif       0.87      0.94      0.91      1754\n",
            "\n",
            "    accuracy                           0.86      2928\n",
            "   macro avg       0.86      0.62      0.64      2928\n",
            "weighted avg       0.86      0.86      0.84      2928\n",
            "\n",
            "\n",
            "--- Inference Sample 1 ---\n",
            "Teks: tidak puas dengan aplikasi ini, jelek, dan banyak bug\n",
            "Rating: 2\n",
            "Hasil Prediksi Sentimen: Negatif\n",
            "\n",
            "--- Inference Sample 2 ---\n",
            "Teks: saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\n",
            "Rating: 4\n",
            "Hasil Prediksi Sentimen: Positif\n",
            "\n",
            "--- Inference Sample 3 ---\n",
            "Teks: fitur aplikasi standar\n",
            "Rating: 3\n",
            "Hasil Prediksi Sentimen: Positif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Logistic Regression mencapai akurasi training 89.68% dan testing 86.00%, menunjukkan performa yang baik dalam klasifikasi sentimen. Performa terbaik ada di kelas Positif (f1-score: 0.91), diikuti Negatif (0.83). Kelas Netral lemah (f1-score: 0.19) akibat recall yang sangat rendah (0.11), kemungkinan disebabkan oleh ketidakseimbangan data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Hasil analisis inference:\n",
        "\n",
        "1. Sample 1:\n",
        "  * Teks: \"tidak puas dengan aplikasi ini, jelek, dan banyak bug\"\n",
        "  * Rating: 2\n",
        "  * Hasil Prediksi Sentimen: Negatif\n",
        "\n",
        "  Kesimpulan: Model berhasil mendeteksi sentimen negatif dengan tepat, berdasarkan kata-kata yang mengandung ketidakpuasan seperti \"jelek\" dan \"banyak bug.\"\n",
        "2. Sample 2:\n",
        "  * Teks: \"saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\"\n",
        "  * Rating: 4\n",
        "  * Hasil Prediksi Sentimen: Positif\n",
        "\n",
        "  Kesimpulan: Model berhasil mengidentifikasi sentimen positif dengan baik, berkat kata-kata yang menunjukkan pengalaman pengguna yang memuaskan seperti \"sangat membantu\" dan \"mudah digunakan.\"\n",
        "3. Sample 3:\n",
        "  * Teks: \"fitur aplikasi standar\"\n",
        "  * Rating: 3\n",
        "  * Hasil Prediksi Sentimen: Positif\n",
        "\n",
        "  Kesimpulan:  Model mengidentifikasi sentimen positif meskipun kata \"standar\" seharusnya menunjukkan netralitas, hal ini bisa dipengaruhi oleh kesamaan konteks dengan sentimen positif lainnya.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Model ini efektif dalam mengklasifikasikan sentimen—Negatif, Positif, dan Netral—dari review dan rating aplikasi. Meskipun memiliki performa yang sangat baik dalam mengidentifikasi sentimen Positif dan Negatif, model ini perlu perbaikan untuk menangani data Netral yang tidak seimbang."
      ],
      "metadata": {
        "id": "u9wmzugcgzRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Random Forest dengan TF-IDF"
      ],
      "metadata": {
        "id": "GS-tiQjNqBFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi untuk melatih dan evaluasi model Random Forest\n",
        "def train_and_evaluate_rf(df):\n",
        "    #Menggabungkan review dengan rating untuk fitur tambahan\n",
        "    df['review_with_rating'] = df['cleaned_review'] + \" \" + df['Rating'].astype(str)\n",
        "\n",
        "    #Ekstraksi fitur dengan TF-IDF Vectorization dengan membatasi jumlah kata unik untuk menghindari overfitting\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['review_with_rating'])\n",
        "    #Menyiapkan label target yang sudah dikategorikan (Negatif, Netral, Positif)\n",
        "    y = df['label']\n",
        "\n",
        "    #Membagi dataset menjadi 80% data latih dan 20% data uji dan random rtate 42\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    #Melatih model menggunakan Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    #Melakukan prediksi terhadap data latih dan data uji\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    #Evaluasi performa model menggunakan akurasi dan classification report\n",
        "    print(\"=== EVALUASI MODEL RANDOM FOREST ===\")\n",
        "    print(f\"Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "    print(f\"Testing Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(\"\\n--- Classification Report (Testing Set) ---\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    return model, vectorizer\n"
      ],
      "metadata": {
        "id": "eKjKX-ygOgaW"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Random Forest digunakan untuk klasifikasi sentimen berdasarkan review dan rating. Data diproses dengan menggabungkan review yang telah dibersihkan dengan rating, lalu diubah menjadi vektor menggunakan TfidfVectorizer. Model dilatih dengan data pelatihan dan diuji pada data uji untuk mengevaluasi akurasi dan menghasilkan laporan klasifikasi."
      ],
      "metadata": {
        "id": "3hW8SqczjcRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi untuk melakukan inference pada teks baru\n",
        "def perform_inference(model, vectorizer, sample_text, sample_rating):\n",
        "    #Menggabungkan teks dan rating menjadi satu input untuk analisis\n",
        "    sample_input = sample_text + \" \" + str(sample_rating)\n",
        "    #Transformasi input ke dalam format vektor menggunakan vectorizer yang sudah dilatih\n",
        "    sample_vector = vectorizer.transform([sample_input])\n",
        "    #Melakukan prediksi menggunakan model\n",
        "    sample_pred = model.predict(sample_vector)\n",
        "    #Menampilkan hasil prediksi\n",
        "    print(f\"Teks: {sample_text}\")\n",
        "    print(f\"Rating: {sample_rating}\")\n",
        "    print(f\"Hasil Prediksi Sentimen: {sample_pred[0]}\")"
      ],
      "metadata": {
        "id": "KSgCHGy8hWea"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi perform_inference bertujuan untuk memproses teks baru yang diberikan bersama dengan ratingnya dan menghasilkan prediksi sentimen berdasarkan model yang sudah dilatih. Teks dan rating digabungkan untuk memberikan konteks yang lebih lengkap bagi model, lalu diubah menjadi vektor melalui TF-IDF vectorizer. Prediksi dilakukan dengan menggunakan model SVM yang telah dilatih, dan hasil sentimen yang diprediksi ditampilkan (Negatif, Positif, atau Netral)."
      ],
      "metadata": {
        "id": "rmGkPpJUjhJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Menjalankan inference dan evaluasi\n",
        "if __name__ == \"__main__\":\n",
        "    model, vectorizer = train_and_evaluate_rf(df)\n",
        "\n",
        "    #Sampel inference (teks & rating)\n",
        "    sample_texts = [\n",
        "        \"tidak puas dengan aplikasi ini, jelek, dan banyak bug\",\n",
        "        \"saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\",\n",
        "        \"fitur aplikasi standar\"\n",
        "    ]\n",
        "\n",
        "    sample_ratings = [2, 4, 3]\n",
        "\n",
        "    #Menjalankan inference setiap teks sampel\n",
        "    for i in range(len(sample_texts)):\n",
        "        print(f\"\\n--- Inference Sample {i+1} ---\")\n",
        "        perform_inference(model, vectorizer, sample_texts[i], sample_ratings[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4116c7b5-f950-41cf-a77b-9b3842b66656",
        "id": "sg0yQzWRhZlR"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== EVALUASI MODEL RANDOM FOREST ===\n",
            "Training Accuracy: 0.9915\n",
            "Testing Accuracy: 0.8548\n",
            "\n",
            "--- Classification Report (Testing Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Negatif       0.79      0.86      0.82      1032\n",
            "      Netral       0.79      0.11      0.19       142\n",
            "     Positif       0.90      0.91      0.90      1754\n",
            "\n",
            "    accuracy                           0.85      2928\n",
            "   macro avg       0.83      0.63      0.64      2928\n",
            "weighted avg       0.85      0.85      0.84      2928\n",
            "\n",
            "\n",
            "--- Inference Sample 1 ---\n",
            "Teks: tidak puas dengan aplikasi ini, jelek, dan banyak bug\n",
            "Rating: 2\n",
            "Hasil Prediksi Sentimen: Negatif\n",
            "\n",
            "--- Inference Sample 2 ---\n",
            "Teks: saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\n",
            "Rating: 4\n",
            "Hasil Prediksi Sentimen: Positif\n",
            "\n",
            "--- Inference Sample 3 ---\n",
            "Teks: fitur aplikasi standar\n",
            "Rating: 3\n",
            "Hasil Prediksi Sentimen: Positif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Random Forest mencapai akurasi training 99.15% dan testing 85.48%, menunjukkan bahwa model sangat baik dalam mempelajari data latih, namun memiliki penurunan akurasi pada data uji, yang biasa terjadi karena overfitting. Performa terbaik ada di kelas Positif (f1-score: 0.90), diikuti oleh Negatif (f1-score: 0.82). Kelas Netral sangat lemah (f1-score: 0.19) akibat recall yang sangat rendah (0.11), yang mengindikasikan masalah ketidakseimbangan data pada kelas ini.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Hasil analisis inference:\n",
        "\n",
        "1. Sample 1:\n",
        "  * Teks: \"tidak puas dengan aplikasi ini, jelek, dan banyak bug\"\n",
        "  * Rating: 2\n",
        "  * Hasil Prediksi Sentimen: Negatif\n",
        "\n",
        "  Kesimpulan: Model berhasil mendeteksi sentimen negatif dengan tepat, berdasarkan kata-kata yang mengandung ketidakpuasan seperti \"jelek\" dan \"banyak bug.\"\n",
        "2. Sample 2:\n",
        "  * Teks: \"saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\"\n",
        "  * Rating: 4\n",
        "  * Hasil Prediksi Sentimen: Positif\n",
        "\n",
        "  Kesimpulan: Model berhasil mengidentifikasi sentimen positif dengan baik, berkat kata-kata yang menunjukkan pengalaman pengguna yang memuaskan seperti \"sangat membantu\" dan \"mudah digunakan.\"\n",
        "3. Sample 3:\n",
        "  * Teks: \"fitur aplikasi standar\"\n",
        "  * Rating: 3\n",
        "  * Hasil Prediksi Sentimen: Positif\n",
        "\n",
        "  Kesimpulan:  Model salah mengidentifikasi sentimen sebagai positif meskipun \"standar\" seharusnya netral. Ini kemungkinan karena kesamaan pola dengan sentimen positif dalam data pelatihan, serta kesulitan model dalam mengenali kelas Netral yang kurang seimbang.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Model ini efektif dalam mengklasifikasikan sentimen—Negatif, Positif, dan Netral—dari review dan rating aplikasi. Meskipun memiliki performa yang sangat baik dalam mengidentifikasi sentimen Positif dan Negatif, model ini perlu perbaikan untuk menangani data Netral yang tidak seimbang."
      ],
      "metadata": {
        "id": "MC2mo1tYibxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Multi-Layer Perceptron (MLP) dengan TF-IDF"
      ],
      "metadata": {
        "id": "T4ePZ6s7zFNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi untuk melatih dan mengevaluasi model\n",
        "def train_and_evaluate_dl_advanced(df):\n",
        "    #Menggabungkan review dengan rating untuk fitur tambahan\n",
        "    df['review_with_rating'] = df['cleaned_review'] + \" \" + df['Rating'].astype(str)\n",
        "\n",
        "    #Ekstraksi fitur dengan TF-IDF Vectorization dengan membatasi jumlah kata unik untuk menghindari overfitting\n",
        "    vectorizer = TfidfVectorizer(max_features=10000)\n",
        "    X = vectorizer.fit_transform(df['review_with_rating']).toarray()\n",
        "\n",
        "    #Label encoding dan kategorisasi untuk klasifikasi multi-kelas\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(df['label'])\n",
        "    y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "    #Membagi dataset menjadi 80% data latih dan 20% data uji dan random rtate 42\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_categorical, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    #Membangun model menggunakan MLP dengan beberapa lapisan Dense (relu) dan Dropout untuk mengurangi overfitting\n",
        "    model = Sequential([\n",
        "        Dense(512, activation='relu', input_dim=X.shape[1]),\n",
        "        Dropout(0.4),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(y_categorical.shape[1], activation='softmax')\n",
        "    ])\n",
        "\n",
        "    #Mengkompilasi model dengan optimizer Adam, loss function categorical_crossentropy untuk klasifikasi multi-kelas, dan metrik akurasi\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    #EarlyStopping untuk mencegah overfitting dengan menghentikan pelatihan jika tidak ada perbaikan pada 'val_loss' selama 3 epoch berturut-turut\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    #Melatih model menggunakan data pelatihan dengan 20 epoch, batch size 64, dan validation_split 0.1 untuk memvalidasi model selama pelatihan\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=20,\n",
        "        batch_size=64,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluasi model pada data training dan testing\n",
        "    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(\"=== EVALUASI MODEL DEEP LEARNING (ADVANCED MLP) ===\")\n",
        "    print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"Testing Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    return model, vectorizer, le"
      ],
      "metadata": {
        "id": "vDbS7LBN1Jf2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model deep learning ini digunakan untuk klasifikasi sentimen berdasarkan review dan rating. Data diproses dengan menggabungkan review dan rating, lalu diubah menjadi vektor menggunakan TF-IDF untuk ekstraksi fitur. Target dikategorikan dan diubah ke format one-hot encoding.\n",
        "\n",
        "Model MLP (Multilayer Perceptron) dengan lapisan Dense dan Dropout digunakan untuk mengurangi overfitting, dioptimalkan dengan Adam dan loss categorical_crossentropy. EarlyStopping menghentikan pelatihan jika tidak ada peningkatan.\n",
        "\n",
        "Evaluasi dilakukan pada data latih dan uji untuk mengukur akurasi model dalam mengklasifikasikan sentimen (Negatif, Netral, Positif)."
      ],
      "metadata": {
        "id": "0ooBrtjpmkOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi untuk melakukan inference\n",
        "def perform_dl_inference(model, vectorizer, label_encoder, text, rating):\n",
        "    #Menggabungkan teks dan rating menjadi satu input untuk analisis\n",
        "    sample_input = text + \" \" + str(rating)\n",
        "    #Transformasi input ke dalam format vektor menggunakan vectorizer yang sudah dilatih berupa array\n",
        "    sample_vector = vectorizer.transform([sample_input]).toarray()\n",
        "    #Menggunakan model untuk memprediksi kelas (sentimen) berdasarkan input yang telah diubah menjadi vektor\n",
        "    pred = model.predict(sample_vector)\n",
        "    #Mengubah hasil prediksi ke label aslinya\n",
        "    label = label_encoder.inverse_transform([pred.argmax()])\n",
        "    #Menampilkan hasil prediksi\n",
        "    print(f\"Teks: {text}\")\n",
        "    print(f\"Rating: {rating}\")\n",
        "    print(f\"Hasil Prediksi Sentimen: {label[0]}\")"
      ],
      "metadata": {
        "id": "rQJBKyzalgWV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi perform_dl_inference digunakan untuk memproses teks baru dan ratingnya untuk menghasilkan prediksi sentimen berdasarkan model deep learning yang telah dilatih. Teks dan rating digabungkan untuk memberikan konteks tambahan, kemudian diubah menjadi vektor menggunakan TF-IDF vectorizer. Model melakukan prediksi sentimen, dan hasilnya (Negatif, Positif, atau Netral) ditampilkan."
      ],
      "metadata": {
        "id": "wT_vuS7HpsN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Menjalankan inference dan evaluasi\n",
        "if __name__ == \"__main__\":\n",
        "    model, vectorizer, le = train_and_evaluate_dl_advanced(df)\n",
        "\n",
        "    #Sample Inference (teks & rating)\n",
        "    sample_texts = [\n",
        "        \"tidak puas dengan aplikasi ini, jelek, dan banyak bug\",\n",
        "        \"saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\",\n",
        "        \"fitur aplikasi standar\"\n",
        "    ]\n",
        "\n",
        "    sample_ratings = [2, 4, 3]\n",
        "\n",
        "    #Menjalankan inference setiap teks sampel\n",
        "    for i in range(len(sample_texts)):\n",
        "        print(f\"\\n--- Inference Sample {i+1} ---\")\n",
        "        perform_dl_inference(model, vectorizer, le, sample_texts[i], sample_ratings[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a8f7c8-8c4e-4b65-8671-9df9a2ee4fa0",
        "id": "L5ar6AOolgs_"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 103ms/step - accuracy: 0.7084 - loss: 0.6970 - val_accuracy: 0.8584 - val_loss: 0.3812\n",
            "Epoch 2/20\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 86ms/step - accuracy: 0.8899 - loss: 0.3213 - val_accuracy: 0.8584 - val_loss: 0.3919\n",
            "Epoch 3/20\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - accuracy: 0.9295 - loss: 0.2022 - val_accuracy: 0.8567 - val_loss: 0.4365\n",
            "Epoch 4/20\n",
            "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 164ms/step - accuracy: 0.9615 - loss: 0.1319 - val_accuracy: 0.8413 - val_loss: 0.4886\n",
            "=== EVALUASI MODEL DEEP LEARNING (ADVANCED MLP) ===\n",
            "Training Accuracy: 0.8922\n",
            "Testing Accuracy: 0.8593\n",
            "\n",
            "--- Inference Sample 1 ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "Teks: tidak puas dengan aplikasi ini, jelek, dan banyak bug\n",
            "Rating: 2\n",
            "Hasil Prediksi Sentimen: Negatif\n",
            "\n",
            "--- Inference Sample 2 ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Teks: saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\n",
            "Rating: 4\n",
            "Hasil Prediksi Sentimen: Positif\n",
            "\n",
            "--- Inference Sample 3 ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Teks: fitur aplikasi standar\n",
            "Rating: 3\n",
            "Hasil Prediksi Sentimen: Positif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model deep learning ini mencapai akurasi pelatihan 89.22% dan akurasi pengujian 85.93%, menunjukkan bahwa model ini cukup baik dalam melakukan klasifikasi sentimen berdasarkan review dan rating.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Hasil analisis inference:\n",
        "\n",
        "1. Sample 1:\n",
        "  * Teks: \"tidak puas dengan aplikasi ini, jelek, dan banyak bug\"\n",
        "  * Rating: 2\n",
        "  * Hasil Prediksi Sentimen: Negatif\n",
        "\n",
        "  Kesimpulan: Model berhasil mendeteksi sentimen negatif dengan tepat, berdasarkan kata-kata yang mengandung ketidakpuasan seperti \"jelek\" dan \"banyak bug.\"\n",
        "2. Sample 2:\n",
        "  * Teks: \"saya merasa aplikasi ini sangat membantu, mudah digunakan dan cepat\"\n",
        "  * Rating: 4\n",
        "  * Hasil Prediksi Sentimen: Positif\n",
        "\n",
        "  Kesimpulan: Model berhasil mengidentifikasi sentimen positif dengan baik, berkat kata-kata yang menunjukkan pengalaman pengguna yang memuaskan seperti \"sangat membantu\" dan \"mudah digunakan.\"\n",
        "3. Sample 3:\n",
        "  * Teks: \"fitur aplikasi standar\"\n",
        "  * Rating: 3\n",
        "  * Hasil Prediksi Sentimen: Positif\n",
        "\n",
        "  Kesimpulan: Meskipun kata \"standar\" umumnya menunjukkan netralitas, model mengklasifikasikan sebagai positif, mungkin karena konteks atau kesamaan dengan sentimen positif lainnya dalam data pelatihan.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Model ini efektif dalam mengklasifikasikan sentimen—baik Negatif maupun Positif—dari review dan rating aplikasi. Meskipun model ini tampil sangat baik dalam mendeteksi sentimen Positif dan Negatif, masih ada beberapa tantangan dalam menangani sentimen Netral, yang dapat dipengaruhi oleh ketidakseimbangan data atau konteks kata-kata yang lebih ambigu."
      ],
      "metadata": {
        "id": "mlZLcgVxqx81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Kesimpulan\n"
      ],
      "metadata": {
        "id": "hW8V0C1gxw5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam analisis sentimen terhadap aplikasi e-commerce Shopee, Lazada, dan Tokped di Indonesia, empat metode (SVC, Logistic Regression, Random Forest, dan MLP) digunakan untuk mengevaluasi sentimen berdasarkan data yang diambil dari Playstore.\n",
        "\n",
        "1. Model terbaik dalam mengidentifikasi sentimen Positif dan Negatif adalah Logistic Regression dan Random Forest, dengan akurasi di atas 86%. Kedua model ini menunjukkan f1-score tinggi di kategori Positif (0.91) dan Negatif (0.83), tetapi masih mengalami kesulitan dalam menangani sentimen Netral.\n",
        "\n",
        "2. SVC dan MLP memiliki akurasi yang sedikit lebih rendah (85%-87%), namun juga efektif dalam mengklasifikasikan sentimen Positif dan Negatif. Netral tetap menjadi tantangan utama bagi semua model, dengan f1-score yang sangat rendah (0.18-0.22).\n",
        "\n",
        "Secara keseluruhan, **Logistic Regression** dan **Random Forest** memberikan hasil yang lebih seimbang antara akurasi dan performa pada kategori yang lebih jelas (Positif dan Negatif). Untuk sentimen Netral, pengumpulan lebih banyak data yang berfokus pada ulasan dengan sentimen netral serta teknik pemrosesan teks lanjutan seperti word embedding atau transfer learning dapat digunakan untuk meningkatkan kemampuan model dalam mengidentifikasi sentimen Netral."
      ],
      "metadata": {
        "id": "IwjNAG4HxFsc"
      }
    }
  ]
}